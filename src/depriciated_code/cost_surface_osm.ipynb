{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc43305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import pyrosm\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "from rasterio import features\n",
    "from rasterio.warp import Resampling\n",
    "from rasterio.transform import Affine\n",
    "import numpy as np\n",
    "from shapely.geometry import box, Point\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.warp import Resampling\n",
    "\n",
    "\n",
    "# Magic command to ensure plots render correctly in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "print(\"All packages imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10192b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Constants ---\n",
    "TARGET_CRS = \"EPSG:32632\"  # UTM Zone 32N\n",
    "BUFFER_METERS = 1000       # 1km buffer\n",
    "PIXEL_SIZE = 10            # 10m resolution\n",
    "AOI_NAME = \"Kanton Schaffhausen\" # Geocoding query\n",
    "\n",
    "# --- Directories ---\n",
    "BASE_DIR = Path.cwd().parent.parent\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "TEMP_DIR = RESULTS_DIR / \"temp_files\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "TEMP_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --- Input File Paths ---\n",
    "# Cost tables\n",
    "OSM_COST_CSV_PATH = DATA_DIR / \"osm_resistance_costs.csv\"\n",
    "CLC_COST_CSV_PATH = DATA_DIR / \"clc_resistance_costs.csv\"\n",
    "\n",
    "# Raw data (will be downloaded)\n",
    "PBF_PATH_DE = DATA_DIR / \"baden-wuerttemberg-latest.osm.pbf\"\n",
    "PBF_PATH_CH = DATA_DIR / \"switzerland-latest.osm.pbf\"\n",
    "\n",
    "# --- Processed Cache File Paths ---\n",
    "PROCESSED_OSM_CACHE = DATA_DIR / \"processed_osm_data.gpkg\"\n",
    "CLC_RECLASSIFIED_PATH = TEMP_DIR / \"temp_raster_clc_reclassified.tif\"\n",
    "CLC_PRECLIPPED_VECTOR_PATH = DATA_DIR / \"U2018_CLC2018_V2020_20u1.gpkg\" \n",
    "\n",
    "# --- Final Output ---\n",
    "FINAL_RASTER = RESULTS_DIR / \"final_resistance_surface.tif\"\n",
    "\n",
    "print(f\"Base Directory:    {BASE_DIR}\")\n",
    "print(f\"Data Directory:    {DATA_DIR}\")\n",
    "print(f\"Results Directory: {RESULTS_DIR}\")\n",
    "print(f\"Temp Directory:    {TEMP_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42bc697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- AOI Definition ---\n",
    "print(f\"1. Defining AOI from '{AOI_NAME}'...\")\n",
    "\n",
    "# Get Schaffhausen boundary in WGS84 via OSMnx geocoding\n",
    "gdf_sh_wgs = ox.geocode_to_gdf(AOI_NAME)\n",
    "\n",
    "# Reproject to target CRS (UTM 32N)\n",
    "gdf_sh_proj = gdf_sh_wgs.to_crs(TARGET_CRS)\n",
    "\n",
    "# Buffer the polygon first\n",
    "print(f\"   Buffering polygon by {BUFFER_METERS}m...\")\n",
    "buffered_polygon = gdf_sh_proj.buffer(BUFFER_METERS)\n",
    "bounds = buffered_polygon.total_bounds\n",
    "\n",
    "# Create a Shapely polygon for the final AOI\n",
    "aoi_poly = box(*bounds)\n",
    "print(f\"   Final rectangular AOI defined.\")\n",
    "\n",
    "# Create a WGS84 version of the AOI for data fetching\n",
    "aoi_poly_wgs = gpd.GeoSeries([aoi_poly], crs=TARGET_CRS).to_crs(\"EPSG:4326\").iloc[0]\n",
    "aoi_bounds_wgs = aoi_poly_wgs.bounds\n",
    "\n",
    "aoi_gdf = gpd.GeoDataFrame(geometry=[aoi_poly], crs=TARGET_CRS)\n",
    "\n",
    "# Plot the AOI vs canton boundary\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "gdf_sh_proj.boundary.plot(ax=ax, edgecolor='blue', label='Canton Boundary')\n",
    "aoi_gdf.boundary.plot(ax=ax, edgecolor='red', linestyle='--', label='AOI Boundary')\n",
    "ax.set_title('AOI vs Canton Schaffhausen Boundary')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a464271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Master Grid Definition ---\n",
    "print(\"2. Defining Master Grid from AOI...\")\n",
    "\n",
    "# Get the bounds from AOI polygon\n",
    "min_x, min_y, max_x, max_y = aoi_poly.bounds\n",
    "\n",
    "# Calculate the grid dimensions (shape)\n",
    "width = math.ceil((max_x - min_x) / PIXEL_SIZE)\n",
    "height = math.ceil((max_y - min_y) / PIXEL_SIZE)\n",
    "\n",
    "# Create the Rasterio 'transform'\n",
    "transform = Affine.translation(min_x, max_y) * Affine.scale(PIXEL_SIZE, -PIXEL_SIZE)\n",
    "\n",
    "# Store the grid metadata\n",
    "master_grid_meta = {\n",
    "    'crs': TARGET_CRS,\n",
    "    'transform': transform,\n",
    "    'height': height,\n",
    "    'width': width,\n",
    "    'driver': 'GTiff'\n",
    "}\n",
    "master_shape = (height, width)\n",
    "\n",
    "print(f\"   Master Grid defined:\")\n",
    "print(f\"   Shape (h, w): {master_shape}\")\n",
    "print(f\"   Resolution: {PIXEL_SIZE}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff74269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Download Raw OSM .pbf Files ---\n",
    "print(\"3. Checking for required .pbf files...\")\n",
    "\n",
    "# Define file paths and download URLs\n",
    "PBF_URL_DE = \"https://download.geofabrik.de/europe/germany/baden-wuerttemberg-latest.osm.pbf\"\n",
    "PBF_URL_CH = \"https://download.geofabrik.de/europe/switzerland-latest.osm.pbf\"\n",
    "files_to_download = [(PBF_PATH_DE, PBF_URL_DE), (PBF_PATH_CH, PBF_URL_CH)]\n",
    "\n",
    "# --- Download function ---\n",
    "def download_file(url, local_path):\n",
    "    print(f\"   Downloading {local_path.name}... (This may take 2-10 minutes)\")\n",
    "    try:\n",
    "        with requests.get(url, stream=True, timeout=30) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(local_path, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192): \n",
    "                    f.write(chunk)\n",
    "        print(f\"   Download complete: {local_path.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"!!! ERROR downloading {url}: {e}\")\n",
    "        if local_path.exists(): os.remove(local_path)\n",
    "        raise\n",
    "\n",
    "# --- Loop and check ---\n",
    "for path, url in files_to_download:\n",
    "    if not path.exists():\n",
    "        print(f\"   '{path.name}' not found.\")\n",
    "        download_file(url, path)\n",
    "    else:\n",
    "        print(f\"   Found '{path.name}'.\")\n",
    "\n",
    "print(\"   All required .pbf files are present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a1ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "# --- 4. Process Corine ---\n",
    "\n",
    "print(f\"4. Checking for processed Corine file ('{CLC_RECLASSIFIED_PATH.name}')...\")\n",
    "\n",
    "if CLC_RECLASSIFIED_PATH.exists():\n",
    "    print(f\"   Found '{CLC_RECLASSIFIED_PATH.name}'. Skipping processing.\")\n",
    "else:\n",
    "    print(f\"   Processing Corine data (Simple Vector Workflow)...\")\n",
    "\n",
    "    DEFAULT_CLC_RESISTANCE = 10000.0 # High-cost/barrier\n",
    "\n",
    "    if not CLC_PRECLIPPED_VECTOR_PATH.exists():\n",
    "        print(f\"!!! ERROR: Pre-clipped CLC Vector file not found at '{CLC_PRECLIPPED_VECTOR_PATH}'\")\n",
    "        raise FileNotFoundError(f\"Missing pre-clipped CLC file: {CLC_PRECLIPPED_VECTOR_PATH}\")\n",
    "\n",
    "    try:\n",
    "        # 1. Load the Resistance map (Lookup 1)\n",
    "        clc_res_map_df = pd.read_csv(CLC_COST_CSV_PATH)\n",
    "        clc_res_map_df['clc_code'] = clc_res_map_df['clc_code'].astype(int)\n",
    "        print(f\"   Loaded {len(clc_res_map_df)} resistance rules.\")\n",
    "\n",
    "        # 2. Load your pre-clipped CLC Vector Data\n",
    "        print(f\"   Loading pre-clipped CLC vector: '{CLC_PRECLIPPED_VECTOR_PATH.name}'...\")\n",
    "        clc_gdf = gpd.read_file(CLC_PRECLIPPED_VECTOR_PATH)\n",
    "        print(f\"   ...Loaded {len(clc_gdf)} polygons.\")\n",
    "\n",
    "        # 3. Reproject the CLC data to the Master Project CRS\n",
    "        clc_proj = clc_gdf.to_crs(master_grid_meta['crs'])\n",
    "        \n",
    "        del clc_gdf\n",
    "        gc.collect()\n",
    "\n",
    "        # 4. Clip the reprojected data to the precise AOI polygon\n",
    "        print(\"   Clipping reprojected CLC to precise AOI geometry...\")\n",
    "        clc_clipped = gpd.clip(clc_proj, aoi_gdf.geometry)\n",
    "        print(f\"   ...Clipping complete. {len(clc_clipped)} polygons remaining.\")\n",
    "        \n",
    "        del clc_proj\n",
    "        gc.collect()\n",
    "        \n",
    "        if clc_clipped.empty:\n",
    "            print(\"!!! ERROR: Clipping resulted in an empty GeoDataFrame. Check AOI CRS.\")\n",
    "            raise ValueError(\"CLC clipping failed.\")\n",
    "\n",
    "        # --- 5. Merge Resistance Values ---\n",
    "        print(\"   Merging resistance values...\")\n",
    "        clc_clipped['Code_18'] = clc_clipped['Code_18'].astype(int)\n",
    "\n",
    "        clc_with_costs = clc_clipped.merge(\n",
    "            clc_res_map_df,\n",
    "            left_on='Code_18',\n",
    "            right_on='clc_code'\n",
    "        )\n",
    "        \n",
    "        if clc_with_costs.empty:\n",
    "            print(\"!!! ERROR: Merging CLC with resistance CSV resulted in no matches.\")\n",
    "            print(\"!!! Check 'Code_18' column in your vector file and 'clc_code' in your CSV.\")\n",
    "            raise ValueError(\"CLC resistance merge failed.\")\n",
    "\n",
    "        # Save Intermediate Vector\n",
    "        temp_vector_path = TEMP_DIR / \"temp_vector_clc_reclassified.gpkg\"\n",
    "        \n",
    "        # Save only essential columns for inspection\n",
    "        clc_with_costs[['Code_18', 'clc_code', 'resistance', 'geometry']].to_file(temp_vector_path, driver=\"GPKG\")\n",
    "        print(f\"   ...Intermediate vector saved to '{temp_vector_path.name}'\")\n",
    "\n",
    "        # 6. Rasterize the vector data\n",
    "        print(\"   Rasterizing vector polygons...\")\n",
    "        \n",
    "        shapes = [(row.geometry, row.resistance) \n",
    "                  for row in clc_with_costs.itertuples() \n",
    "                  if row.geometry is not None and not row.geometry.is_empty]\n",
    "\n",
    "        clc_reclassified_data = np.full(master_shape, DEFAULT_CLC_RESISTANCE, dtype=np.float32)\n",
    "\n",
    "        features.rasterize(\n",
    "            shapes=shapes,\n",
    "            out=clc_reclassified_data,\n",
    "            transform=master_grid_meta['transform'],\n",
    "            all_touched=True,\n",
    "            fill=DEFAULT_CLC_RESISTANCE,\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # 7. Save the final reclassified raster\n",
    "        # (This path remains unchanged as it is a FINAL output, not temporary)\n",
    "        meta_to_save = master_grid_meta.copy()\n",
    "        meta_to_save.update(dtype=np.float32, count=1, nodata=None)\n",
    "        \n",
    "        with rasterio.open(CLC_RECLASSIFIED_PATH, 'w', **meta_to_save) as dst:\n",
    "            dst.write(clc_reclassified_data, 1)\n",
    "        print(f\"   ...Corine fallback raster saved to '{CLC_RECLASSIFIED_PATH.name}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"!!! Error processing Corine vector data: {e} !!!\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1673ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Process OSM Data ---\n",
    "print(f\"5. Checking for processed OSM cache ('{PROCESSED_OSM_CACHE.name}')...\")\n",
    "\n",
    "# Check if a pre-processed version of the OSM data exists (e.g., from a previous run).\n",
    "# This is a critical efficiency check to save hours of processing time.\n",
    "if PROCESSED_OSM_CACHE.exists():\n",
    "    print(f\"   Found fast-loading cache file. Loading...\")\n",
    "    # Load the cached GeoPackage (GPKG) file directly into a GeoDataFrame\n",
    "    osm_gdf = gpd.read_file(PROCESSED_OSM_CACHE)\n",
    "    print(f\"   ...Cache loaded. Fetched {len(osm_gdf)} features.\")\n",
    "else:\n",
    "    print(f\"   Cache file not found. Starting full data processing...\")\n",
    "    \n",
    "    # 1. Prepare Tags and Bounding Box\n",
    "    # Load the resistance cost rules\n",
    "    resistance_df = pd.read_csv(OSM_COST_CSV_PATH)\n",
    "    # Extract all unique 'osm_key' tags (e.g., 'landuse', 'highway') from your CSV rules.\n",
    "    needed_keys = resistance_df['osm_key'].unique().tolist()\n",
    "    # Create a pyrosm-compatible filter dictionary {key: True} to fetch *all* values for those keys.\n",
    "    tags_filter = {key: True for key in needed_keys}\n",
    "    # Convert the WGS84 bounding box tuple (minx, miny, maxx, maxy) to a list for pyrosm.\n",
    "    bbox_wgs_list = [aoi_bounds_wgs[0], aoi_bounds_wgs[1], aoi_bounds_wgs[2], aoi_bounds_wgs[3]]\n",
    "\n",
    "    # 2. Extract Data for Germany (Baden-Württemberg)\n",
    "    print(\"   Processing German data (Baden-Württemberg)... THIS IS SLOW.\")\n",
    "    # Initialize pyrosm object with the German PBF file, clipped to the AOI box.\n",
    "    osm_de = pyrosm.OSM(str(PBF_PATH_DE), bounding_box=bbox_wgs_list) \n",
    "    # Extract all features matching the defined tags (e.g., all roads, all forests).\n",
    "    osm_gdf_de = osm_de.get_data_by_custom_criteria(custom_filter=tags_filter)\n",
    "    print(\"   ...German data complete.\")\n",
    "\n",
    "    # 3. Extract Data for Switzerland (Schaffhausen area)\n",
    "    print(\"   Processing Swiss data... THIS IS SLOW.\")\n",
    "    # Initialize pyrosm object with the Swiss PBF file, clipped to the AOI box.\n",
    "    osm_ch = pyrosm.OSM(str(PBF_PATH_CH), bounding_box=bbox_wgs_list)\n",
    "    # Extract all features matching the defined tags.\n",
    "    osm_gdf_ch = osm_ch.get_data_by_custom_criteria(custom_filter=tags_filter)\n",
    "    print(\"   ...Swiss data complete.\")\n",
    "\n",
    "    # 4. Combine and Clean\n",
    "    print(\"   Combining and cleaning data...\")\n",
    "    # Concatenate the GeoDataFrames from Germany and Switzerland.\n",
    "    # .drop_duplicates(subset=['id']) removes any features duplicated near the border.\n",
    "    osm_gdf_wgs = pd.concat([osm_gdf_de, osm_gdf_ch]).drop_duplicates(subset=['id'])\n",
    "\n",
    "    # Delete large objects and force garbage collection to free memory after processing PBFs.\n",
    "    del osm_gdf_de, osm_gdf_ch, osm_de, osm_ch\n",
    "    gc.collect()\n",
    "\n",
    "    # Filter columns to keep only 'id', 'geometry', and the specific tags required for resistance assignment.\n",
    "    needed_cols = ['id', 'geometry'] + needed_keys\n",
    "    cols_to_keep = [col for col in needed_cols if col in osm_gdf_wgs.columns]\n",
    "    osm_gdf_wgs = osm_gdf_wgs[cols_to_keep]\n",
    "\n",
    "    # 5. Reproject to Master CRS\n",
    "    print(\"   Reprojecting OSM data...\")\n",
    "    # Convert the data from WGS84 (latitude/longitude, the OSM standard) to the project's CRS (EPSG:32632).\n",
    "    # This is essential for distance calculations and aligning with the master grid.\n",
    "    osm_gdf = osm_gdf_wgs.to_crs(TARGET_CRS)\n",
    "\n",
    "    # 6. Final Data Integrity Checks\n",
    "    # Remove rows where geometry is missing (notna()).\n",
    "    osm_gdf = osm_gdf[osm_gdf.geometry.notna()]\n",
    "    # Filter to keep only features that are usable in the resistance model (Polygons for landcover, LineStrings for roads/rivers).\n",
    "    osm_gdf = osm_gdf[osm_gdf.geometry.geom_type.isin(['Polygon', 'LineString', 'MultiPolygon', 'MultiLineString'])]\n",
    "    print(f\"   Fetched and processed {len(osm_gdf)} relevant OSM features.\")\n",
    "    \n",
    "    # 7. Cache the Result\n",
    "    print(f\"   Saving processed data to cache file: '{PROCESSED_OSM_CACHE.name}'\")\n",
    "    # Save the cleaned, reprojected data as a GeoPackage for fast loading next time.\n",
    "    osm_gdf.to_file(PROCESSED_OSM_CACHE, driver=\"GPKG\")\n",
    "    print(\"   ...Cache file saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47346b7b",
   "metadata": {},
   "source": [
    "natural water makes problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cc8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "from rasterio.enums import MergeAlg\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- 1. Setup Paths and Metadata ---\n",
    "print(\"6. Setting up for intermediate file generation...\")\n",
    "\n",
    "# Define and create the new temp directory\n",
    "TEMP_DIR = os.path.join(RESULTS_DIR, \"temp_files\")\n",
    "os.makedirs(TEMP_DIR, exist_ok=True)\n",
    "print(f\"   ...Intermediate files will be saved in: {TEMP_DIR}\")\n",
    "\n",
    "# Load the resistance rules from our new CSV\n",
    "resistance_df = pd.read_csv(OSM_COST_CSV_PATH)\n",
    "\n",
    "# Metadata for all new intermediate rasters (based on master grid)\n",
    "meta_to_save = master_grid_meta.copy()\n",
    "meta_to_save.update(dtype=np.float32, count=1, nodata=0.0) # Use 0.0 as NoData\n",
    "\n",
    "# --- 2. Generate Intermediate Files for each OSM Key ---\n",
    "print(\"7. Generating intermediate vector and raster files for each osm_key...\")\n",
    "\n",
    "# Get all unique keys from the CSV\n",
    "all_osm_keys = resistance_df['osm_key'].unique()\n",
    "\n",
    "for osm_key in all_osm_keys:\n",
    "    print(f\"\\nProcessing key: '{osm_key}'\")\n",
    "    \n",
    "    # Get all rules from the CSV for this specific key\n",
    "    key_rules = resistance_df[resistance_df['osm_key'] == osm_key].sort_values('priority', ascending=True)\n",
    "    \n",
    "    if key_rules.empty:\n",
    "        print(f\"  ...No rules found for '{osm_key}' in CSV. Skipping.\")\n",
    "        continue\n",
    "        \n",
    "    # Check if this key even exists as a column in the main GeoDataFrame\n",
    "    if osm_key not in osm_gdf.columns:\n",
    "        print(f\"  ...Column '{osm_key}' not in GeoDataFrame. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # --- 2a. Create Intermediate Vector File (.gpkg) ---\n",
    "    \n",
    "    # Get all unique values we need to filter for this key\n",
    "    relevant_values = key_rules['osm_value'].unique()\n",
    "    \n",
    "    if 'yes' in relevant_values:\n",
    "        # Handle tags like 'building=yes' which means any non-null value\n",
    "        features_for_key_gdf = osm_gdf[osm_gdf[osm_key].notna()].copy()\n",
    "    else:\n",
    "        # Filter for all other specific values (e.g., 'highway' in ['path', 'residential', ...])\n",
    "        features_for_key_gdf = osm_gdf[osm_gdf[osm_key].isin(relevant_values)].copy()\n",
    "\n",
    "    if features_for_key_gdf.empty:\n",
    "        print(f\"  ...No geometries found in GDF for key '{osm_key}'. Skipping.\")\n",
    "        continue\n",
    "        \n",
    "    # Add the resistance value to the intermediate GDF for inspection in QGIS\n",
    "    # Create a mapping dictionary {value: resistance}\n",
    "    value_resistance_map = key_rules.set_index('osm_value')['resistance'].to_dict()\n",
    "    \n",
    "    if 'yes' in relevant_values:\n",
    "         # For 'yes', apply the resistance to *all* non-null values\n",
    "         resistance_val = value_resistance_map.get('yes', 0) # Get resistance for 'yes'\n",
    "         features_for_key_gdf['resistance'] = resistance_val\n",
    "    else:\n",
    "         features_for_key_gdf['resistance'] = features_for_key_gdf[osm_key].map(value_resistance_map)\n",
    "\n",
    "    # Save the intermediate vector file\n",
    "    temp_vector_path = os.path.join(TEMP_DIR, f\"temp_vector_{osm_key}.gpkg\")\n",
    "    try:\n",
    "        # We only need a few columns for inspection\n",
    "        cols_to_save = ['id', osm_key, 'geometry', 'resistance']\n",
    "        features_for_key_gdf[cols_to_save].to_file(temp_vector_path, driver=\"GPKG\")\n",
    "        print(f\"  ...Saved intermediate vector: {os.path.basename(temp_vector_path)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ...ERROR saving vector {temp_vector_path}: {e}\")\n",
    "\n",
    "    # --- 2b. Create Intermediate Raster File (.tif) ---\n",
    "    \n",
    "    # Initialize an empty raster array for this key\n",
    "    key_raster = np.full(master_shape, 0.0, dtype=np.float32)\n",
    "    temp_raster_path = os.path.join(TEMP_DIR, f\"temp_raster_{osm_key}.tif\")\n",
    "\n",
    "    # Now, iterate through the rules for this key (which are sorted by priority)\n",
    "    # This will \"burn\" features on top of each other *correctly*\n",
    "    # (e.g., 'highway=motorway' will burn over 'highway=path')\n",
    "    \n",
    "    print(f\"  ...Rasterizing {len(key_rules)} rules for '{osm_key}' by priority...\")\n",
    "    for _, row in key_rules.iterrows():\n",
    "        key, value, resistance = row['osm_key'], row['osm_value'], row['resistance']\n",
    "        \n",
    "        # We can re-use the GDF we filtered earlier\n",
    "        if value == 'yes':\n",
    "            features_to_rasterize = features_for_key_gdf # Already filtered for notna()\n",
    "        else:\n",
    "            features_to_rasterize = features_for_key_gdf[features_for_key_gdf[key] == value]\n",
    "        \n",
    "        if features_to_rasterize.empty:\n",
    "            continue\n",
    "\n",
    "        # Create (geom, value) pairs for rasterio\n",
    "        shapes = [(geom, resistance) for geom in features_to_rasterize.geometry]\n",
    "        \n",
    "        # Rasterize (burn) these features into the key_raster\n",
    "        features.rasterize(\n",
    "            shapes=shapes,\n",
    "            out=key_raster,\n",
    "            transform=master_grid_meta['transform'],\n",
    "            merge_alg=MergeAlg.replace,\n",
    "            all_touched=True, # Essential for linear features (roads, rivers, barriers)\n",
    "            dtype=np.float32\n",
    "        )\n",
    "    \n",
    "    # Save the final intermediate raster for this key\n",
    "    with rasterio.open(temp_raster_path, 'w', **meta_to_save) as dst:\n",
    "        dst.write(key_raster, 1)\n",
    "    print(f\"  ...Saved intermediate raster: {os.path.basename(temp_raster_path)}\")\n",
    "\n",
    "print(\"\\nIntermediate file generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a39b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Combine All Rasters ---\n",
    "print(\"7. Combining all intermediate rasters into final surface...\")\n",
    "\n",
    "try:\n",
    "    # --- 1. Load the Base CLC Fallback Raster ---\n",
    "    print(f\"   ...Loading CLC fallback raster: {CLC_RECLASSIFIED_PATH.name}\")\n",
    "    with rasterio.open(CLC_RECLASSIFIED_PATH) as src:\n",
    "        # This is the base map.\n",
    "        final_raster = src.read(1).astype(np.float32)\n",
    "        meta = src.meta.copy()\n",
    "        meta.update(dtype=np.float32, nodata=None) # Final raster has no nodata\n",
    "    \n",
    "    # --- 2. Define Intermediate File Location ---\n",
    "    TEMP_DIR = os.path.join(RESULTS_DIR, \"temp_files\")\n",
    "    \n",
    "    # Find all the intermediate OSM rasters we just created\n",
    "    # We use glob to get a list of all matching files\n",
    "    osm_raster_files = list(Path(TEMP_DIR).glob(\"temp_raster_*.tif\"))\n",
    "    \n",
    "    if not osm_raster_files:\n",
    "        print(f\"!!! ERROR: No 'temp_raster_*.tif' files found in {TEMP_DIR}\")\n",
    "        print(\"!!! Please re-run the previous cell (Generate Intermediate Rasters) !!!\")\n",
    "    \n",
    "    print(f\"   ...Found {len(osm_raster_files)} intermediate OSM rasters to combine.\")\n",
    "\n",
    "    # --- 3. Loop, Load, and Combine ---\n",
    "    for raster_file in osm_raster_files:\n",
    "        print(f\"   ...Merging: {raster_file.name}\")\n",
    "        with rasterio.open(raster_file) as src:\n",
    "            # Read the OSM layer\n",
    "            osm_layer = src.read(1)\n",
    "            \n",
    "            # Clean the layer: our nodata value was 0.0\n",
    "            # np.nan_to_num is a fast way to replace any potential NaNs with 0.0\n",
    "            osm_layer = np.nan_to_num(osm_layer, nan=0.0)\n",
    "            \n",
    "            # Use np.maximum to combine.\n",
    "            # This burns barriers (high values) over landcover (low values)\n",
    "            # AND fills gaps (where osm_layer is 0) with CLC values.\n",
    "            final_raster = np.maximum(final_raster, osm_layer)\n",
    "\n",
    "    # --- 4. Save the Final Combined Raster ---\n",
    "    with rasterio.open(FINAL_RASTER, 'w', **meta) as dst:\n",
    "        dst.write(final_raster, 1)\n",
    "        \n",
    "    print(f\"\\n   SUCCESS: Final resistance surface saved to '{FINAL_RASTER}'\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"!!! ERROR: Could not find base CLC file: {e}\")\n",
    "    print(\"!!! Please re-run the CLC processing cell. !!!\")\n",
    "except Exception as e:\n",
    "    print(f\"!!! An unexpected error occurred during combination: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da562cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualize Final Result ---\n",
    "print(\"Plotting final cost surface...\")\n",
    "\n",
    "try:\n",
    "    with rasterio.open(FINAL_RASTER) as src:\n",
    "        cost_data = src.read(1)\n",
    "\n",
    "        print(f'   Min value: {np.min(cost_data):.2f}, Max value: {np.max(cost_data):.2f}')\n",
    "\n",
    "        # Print amount of nan values\n",
    "        nan_count = np.isnan(cost_data).sum()\n",
    "        print(f'   Number of NaN values in final raster: {nan_count}')\n",
    "\n",
    "        print(min(cost_data.flatten()), max(cost_data.flatten()))\n",
    "        \n",
    "        # Use a log scale for visualization\n",
    "        cost_data_log = np.log1p(cost_data)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        \n",
    "        im = rasterio.plot.show(\n",
    "            cost_data_log,\n",
    "            transform=src.transform,\n",
    "            ax=ax,\n",
    "            cmap='RdYlGn_r'\n",
    "        )\n",
    "        \n",
    "        cbar = fig.colorbar(im.images[0], ax=ax, shrink=0.7)\n",
    "        cbar.set_label('Log(Resistance Cost)')\n",
    "        \n",
    "        # Plot the canton boundary on top\n",
    "        gdf_sh_proj.boundary.plot(ax=ax, color='blue', linestyle='--', linewidth=2, label='Canton Boundary')\n",
    "        \n",
    "        ax.legend()\n",
    "        ax.set_title(\"Final Cost Surface (Log Scale)\")\n",
    "        ax.set_xlabel(\"Easting (m)\")\n",
    "        ax.set_ylabel(\"Northing (m)\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "except NameError:\n",
    "    print(\"!!! ERROR: 'gdf_sh_proj' not found. Please re-run Cell 4 (AOI Definition).\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"!!! ERROR: File not found at '{FINAL_RASTER}'\")\n",
    "    print(\"Please make sure Cell 10 (Combine Final Raster) ran successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeabd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot water courses and water bodies from the clc fallback raster\n",
    "import rasterio\n",
    "from rasterio.plot import show as rioshow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# --- ASSUMPTIONS (Ensure these variables are defined) ---\n",
    "# CLC_RECLASSIFIED_PATH (Path object to your CLC reclassified raster)\n",
    "# aoi_gdf (GeoDataFrame of the AOI boundary)\n",
    "\n",
    "# Define the target resistance value for water features (511 and 512 in our cost table)\n",
    "WATER_RESISTANCE_VALUE = 5000\n",
    "\n",
    "print(f\"Loading CLC fallback raster from {CLC_RECLASSIFIED_PATH.name}\")\n",
    "\n",
    "with rasterio.open(CLC_RECLASSIFIED_PATH) as src:\n",
    "    clc_data = src.read(1)\n",
    "    # The raster transform is necessary for accurate plotting\n",
    "    transform = src.transform \n",
    "    clc_crs = src.crs\n",
    "\n",
    "# --- 1. Create a Mask for Water Features ---\n",
    "# Isolate pixels that have the exact water resistance value (800)\n",
    "water_mask = (clc_data == WATER_RESISTANCE_VALUE)\n",
    "\n",
    "# Create a new array: where the mask is TRUE, keep the water value (800); \n",
    "# otherwise, set to NaN for transparency in the plot\n",
    "water_only_array = np.where(water_mask, WATER_RESISTANCE_VALUE, np.nan) \n",
    " \n",
    "# --- 2. Plot the Water Features ---\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "# Define a simple colormap for just the water (blue)\n",
    "cmap = mcolors.ListedColormap(['#007FFF']) # A specific shade of blue\n",
    "bounds = [WATER_RESISTANCE_VALUE, WATER_RESISTANCE_VALUE + 1]\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# Plot the AOI boundary for geographic context\n",
    "aoi_gdf.to_crs(clc_crs).plot(ax=ax, facecolor='none', edgecolor='black', linewidth=1, linestyle='--', label='AOI Boundary')\n",
    "\n",
    "# Plot the masked water data\n",
    "rioshow(\n",
    "    water_only_array,\n",
    "    transform=transform,\n",
    "    ax=ax,\n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    title=f\"CLC Fallback Water Features Only (Resistance {WATER_RESISTANCE_VALUE})\",\n",
    "    interpolation='none'\n",
    ")\n",
    "\n",
    "# Annotate the plot\n",
    "ax.set_xlabel(\"Easting (m)\")\n",
    "ax.set_ylabel(\"Northing (m)\")\n",
    "\n",
    "# Create a custom legend handle\n",
    "blue_patch = mpatches.Patch(color='#007FFF', label=f'Water Courses/Bodies (Res={WATER_RESISTANCE_VALUE})')\n",
    "ax.legend(handles=[blue_patch], loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pa2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
